{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b039bf32",
   "metadata": {},
   "source": [
    "# Fireworks Platform Demo\n",
    "\n",
    "A fast tour of Fireworks with runnable examples.\n",
    "\n",
    "You’ll explore:\n",
    "- Model Library and UI\n",
    "- OpenAI-compatible SDK for text, vision, and embeddings\n",
    "- Structured output (JSON, Grammar) and function calling\n",
    "- Deployments with firectl and a quick tour of fine-tuning\n",
    "\n",
    "Helpful links:\n",
    "- Fireworks Docs: [Getting started](https://fireworks.ai/docs/getting-started/introduction) · [Model Library](https://fireworks.ai/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a7edf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup\n",
    "\n",
    "This demo uses the Fireworks SDK and OpenAI SDK. Before running cells, set your environment variable `FIREWORKS_API_KEY`.\n",
    "\n",
    "Install dependencies using uv (fast package manager):\n",
    "\n",
    "```bash\n",
    "uv venv .venv\n",
    "source .venv/bin/activate\n",
    "uv pip install --upgrade fireworks-ai openai requests pillow umap-learn matplotlib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28348d91",
   "metadata": {},
   "source": [
    "## Section 1: Querying text models\n",
    "\n",
    "Fireworks supports an OpenAI-compatible API. Point the OpenAI client at Fireworks by setting the base URL, then choose a model from the Model Library.\n",
    "\n",
    "- Base URL: `https://api.fireworks.ai/inference/v1`\n",
    "- Example model: `accounts/fireworks/models/deepseek-v3p1`\n",
    "- Docs: [Querying text models](https://fireworks.ai/docs/guides/querying-text-models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982abc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text: Fireworks via OpenAI-compatible client\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"FIREWORKS_API_KEY\"], base_url=\"https://api.fireworks.ai/inference/v1\")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"accounts/fireworks/models/deepseek-v3p1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a haiku about a dog who likes AI\"}],\n",
    ")\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c271b27f",
   "metadata": {},
   "source": [
    "## Section 1: Vision-language (image + text)\n",
    "\n",
    "Send an image and a prompt to a multi-modal model.\n",
    "\n",
    "- Example model: `accounts/fireworks/models/qwen2p5-vl-32b-instruct`\n",
    "- Docs: [Vision language models](https://fireworks.ai/docs/guides/querying-vision-language-models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vision-language: local image example\n",
    "import os, base64\n",
    "from openai import OpenAI\n",
    "from matplotlib import image as mplimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"FIREWORKS_API_KEY\"], base_url=\"https://api.fireworks.ai/inference/v1\")\n",
    "\n",
    "image_path = \"cat-in-a-hat.png\"\n",
    "img = mplimg.imread(image_path)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "with open(image_path, \"rb\") as f:\n",
    "    b64 = base64.b64encode(f.read()).decode()\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image in one concise sentence.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64}\"}},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"accounts/fireworks/models/qwen2p5-vl-32b-instruct\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3b7611",
   "metadata": {},
   "source": [
    "## Section 1: Embeddings\n",
    "\n",
    "Turn text into vectors for search and RAG.\n",
    "\n",
    "- Example model: `fireworks/qwen3-30b-a3b`\n",
    "- Docs: [Embeddings](https://docs.fireworks.ai/guides/querying-embeddings-models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings with Fireworks (OpenAI-compatible)\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"https://api.fireworks.ai/inference/v1\",\n",
    "    api_key=os.environ[\"FIREWORKS_API_KEY\"],\n",
    ")\n",
    "response = client.embeddings.create(\n",
    "  model=\"fireworks/qwen3-30b-a3b\",\n",
    "  input=\"Spiderman was a particularly entertaining movie.\",\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00315713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Fireworks (OpenAI-compatible) client\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.fireworks.ai/inference/v1\",\n",
    "    api_key=os.environ[\"FIREWORKS_API_KEY\"],\n",
    ")\n",
    "\n",
    "# 1) Fifteen texts across 3 semantic clusters (5 each)\n",
    "texts = [\n",
    "    # Cluster A: Movies / Superheroes (5)\n",
    "    \"The latest Spider-Man reboot had dazzling visuals and witty dialogue, especially during the city-swing chase.\",\n",
    "    \"Critics praised the superhero film’s character arc and the emotional stakes between the masked hero and his mentor.\",\n",
    "    \"I loved the comic-book set pieces, the web-swinging, and the playful banter that kept the action energetic.\",\n",
    "    \"The villain’s motivations felt grounded, and the mid-credits scene set up a bold twist for the next installment.\",\n",
    "    \"Sound design in the rooftop battle mixed orchestral swells with gritty street noise to heighten tension.\",\n",
    "\n",
    "    # Cluster B: Cooking / Pasta (5)\n",
    "    \"To make cacio e pepe, toast the pepper, add starchy pasta water, then fold in finely grated Pecorino until silky.\",\n",
    "    \"Fresh tagliatelle with slow-simmered ragù develops depth—start with onions, carrots, celery, and a gentle reduction.\",\n",
    "    \"Al dente spaghetti with cherry tomatoes, basil, and garlic shines when you emulsify the sauce with pasta water.\",\n",
    "    \"Finish carbonara off-heat so the eggs turn glossy, then adjust with a splash of pasta water to keep it velvety.\",\n",
    "    \"For pesto, chill the bowl and pulse briefly to prevent bruising the basil; loosen with a ladle of hot pasta water.\",\n",
    "\n",
    "    # Cluster C: Outdoors / Hiking (5)\n",
    "    \"The ridge hike offers sweeping valley views; pack layers, check the forecast, and bring enough water for the climb.\",\n",
    "    \"We pitched the tent near a quiet alpine lake, then followed switchbacks to the summit just before golden hour.\",\n",
    "    \"Trail etiquette matters—yield to uphill hikers, stay on marked paths, and carry out everything you bring in.\",\n",
    "    \"Microspikes helped on icy sections above tree line; we navigated cairns until the clouds finally broke.\",\n",
    "    \"A pre-dawn start kept us cool; we logged GPS waypoints and kept snacks handy for the last steep push.\",\n",
    "]\n",
    "\n",
    "labels = np.array(\n",
    "    [\"Movies/Comics\"] * 5 +\n",
    "    [\"Cooking/Pasta\"] * 5 +\n",
    "    [\"Hiking/Outdoors\"] * 5\n",
    ")\n",
    "\n",
    "# 2) Batch embeddings\n",
    "emb_resp = client.embeddings.create(\n",
    "    model=\"fireworks/qwen3-30b-a3b\",\n",
    "    input=texts\n",
    ")\n",
    "embeddings = np.array([d.embedding for d in emb_resp.data], dtype=np.float32)\n",
    "\n",
    "# 3) UMAP to 3D (cosine distance works well for text embeddings)\n",
    "reducer = umap.UMAP(n_components=3, metric=\"cosine\", random_state=42)\n",
    "xyz = reducer.fit_transform(embeddings)\n",
    "\n",
    "# 4) Interactive 3D plot with Plotly\n",
    "fig = px.scatter_3d(\n",
    "    x=xyz[:, 0],\n",
    "    y=xyz[:, 1],\n",
    "    z=xyz[:, 2],\n",
    "    color=labels,\n",
    "    hover_name=[f\"{i+1}. {lbl}\" for i, lbl in enumerate(labels)],\n",
    "    hover_data={\"Text\": texts},\n",
    "    title=\"UMAP (3D) of 15 Text Embeddings\"\n",
    ")\n",
    "fig.update_traces(marker=dict(size=6, opacity=0.9))\n",
    "fig.update_layout(width=900, height=500, scene=dict(xaxis_title=\"UMAP-1\", yaxis_title=\"UMAP-2\", zaxis_title=\"UMAP-3\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f21c432",
   "metadata": {},
   "source": [
    "## Section 1: Function calling\n",
    "\n",
    "Let the model request a tool with arguments; you execute it and feed the result back.\n",
    "\n",
    "- Docs: [Tool / Function calling](https://fireworks.ai/docs/guides/function-calling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcaadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fireworks import LLM\n",
    "\n",
    "# Define function schemas\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get current weather for a location\"\"\"\n",
    "    # Mock weather data\n",
    "    weather_data = {\n",
    "        \"New York\": \"Sunny, 72°F\",\n",
    "        \"London\": \"Cloudy, 15°C\",\n",
    "        \"Tokyo\": \"Rainy, 20°C\"\n",
    "    }\n",
    "    return weather_data.get(location, \"Weather data not available\")\n",
    "\n",
    "\n",
    "def count_letter_occurrences(word: str, letter: str) -> int:\n",
    "    \"\"\"Count how many times a given letter occurs in a word\"\"\"\n",
    "    if not word or not letter:\n",
    "        return 0\n",
    "    return word.count(letter)\n",
    "\n",
    "\n",
    "# Available functions mapping\n",
    "available_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"count_letter_occurrences\": count_letter_occurrences\n",
    "}\n",
    "\n",
    "# Function definitions for the LLM (using correct \"tools\" format)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city name\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"count_letter_occurrences\",\n",
    "            \"description\": \"Count how many times a given letter occurs in a word\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"word\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The word to check\"\n",
    "                    },\n",
    "                    \"letter\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The letter to count\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"word\", \"letter\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = LLM(model=\"accounts/fireworks/models/glm-4p5\", deployment_type=\"serverless\", api_key=os.environ[\"FIREWORKS_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c34a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Weather query\n",
    "import json\n",
    "\n",
    "print(\"=== Example 1: Weather Query ===\")\n",
    "\n",
    "# Initialize the messages list\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant. You have access to a couple of tools, use them when needed.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Tokyo?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = llm.chat.completions.create(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Check if the model wants to call a tool/function\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    print(f\"LLM wants to call: {function_name}\")\n",
    "    print(f\"With arguments: {function_args}\")\n",
    "\n",
    "    # Execute the function\n",
    "    function_response = available_functions[function_name](**function_args)\n",
    "    print(f\"Function result: {function_response}\")\n",
    "\n",
    "    # Add the assistant's tool call to the conversation\n",
    "    messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\",\n",
    "        \"tool_calls\": [tool_call.model_dump() for tool_call in response.choices[0].message.tool_calls]\n",
    "    })\n",
    "\n",
    "    # Add the function result to the conversation\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps(function_response) if isinstance(function_response, dict) else str(function_response)\n",
    "    })\n",
    "\n",
    "    # Get the final response\n",
    "    final_response = llm.chat.completions.create(\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    print(f\"Final response: {final_response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Count letter occurrences\n",
    "import json\n",
    "\n",
    "print(\"\\n=== Example 2: Count Letter Occurrences ===\")\n",
    "\n",
    "# Initialize messages for letter counter\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant. You have access to a couple of tools, use them when needed.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How many times does the letter 'p' appear in the word 'apple'?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = llm.chat.completions.create(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    print(f\"LLM wants to call: {function_name}\")\n",
    "    print(f\"With arguments: {function_args}\")\n",
    "\n",
    "    # Execute the function\n",
    "    function_response = available_functions[function_name](**function_args)\n",
    "    print(f\"Function result: {function_response}\")\n",
    "\n",
    "    # Add the assistant's tool call to the conversation\n",
    "    messages.append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\",\n",
    "        \"tool_calls\": [tool_call.model_dump() for tool_call in response.choices[0].message.tool_calls]\n",
    "    })\n",
    "\n",
    "    # Add the function result to the conversation\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps(function_response) if isinstance(function_response, dict) else str(function_response)\n",
    "    })\n",
    "\n",
    "    # Get final response\n",
    "    final_response = llm.chat.completions.create(\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    print(f\"Final response: {final_response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2613f4",
   "metadata": {},
   "source": [
    "## Section 1: JSON mode\n",
    "\n",
    "Ask for structured JSON that is easy to parse.\n",
    "\n",
    "- Docs: [JSON mode](https://fireworks.ai/docs/structured-responses/structured-response-formatting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b99aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal JSON mode with Fireworks LLM + Pydantic\n",
    "import os, json\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "from fireworks import LLM  # ✅ Fireworks SDK\n",
    "\n",
    "# --- Schema ---\n",
    "class ProductInfo(BaseModel):\n",
    "    title: str\n",
    "    category: str\n",
    "    price: str\n",
    "    features: List[str]\n",
    "\n",
    "# --- Client ---\n",
    "FIREWORKS_API_KEY = os.environ[\"FIREWORKS_API_KEY\"]\n",
    "MODEL_ID = \"accounts/fireworks/models/deepseek-v3p1\"\n",
    "\n",
    "llm = LLM(model=MODEL_ID, deployment_type=\"serverless\", api_key=FIREWORKS_API_KEY)\n",
    "\n",
    "# --- Example product blurb ---\n",
    "product_blurb = \"\"\"\n",
    "Introducing the Acme BreezeMax Pro, a whisper-quiet 16\" smart pedestal fan.\n",
    "AI auto mode adjusts airflow to room conditions. Three colors: black, white, green.\n",
    "Includes a 2-year warranty. MSRP $139. Perfect for large rooms.\n",
    "\"\"\"\n",
    "\n",
    "# --- Messages ---\n",
    "system_msg = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are a precise information extraction assistant. \"\n",
    "        \"Return ONLY a JSON object that matches the schema. \"\n",
    "        \"Do not include extra fields.\"\n",
    "    ),\n",
    "}\n",
    "user_msg = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"Extract structured product information from this summary:\\n\\n{product_blurb}\",\n",
    "}\n",
    "\n",
    "# --- Call model ---\n",
    "resp = llm.chat.completions.create(\n",
    "    messages=[system_msg, user_msg],\n",
    "    temperature=0.1,\n",
    "    response_format={\"type\": \"json_object\", \"schema\": ProductInfo.model_json_schema()},\n",
    ")\n",
    "\n",
    "# --- Validate ---\n",
    "raw = resp.choices[0].message.content\n",
    "try:\n",
    "    data = json.loads(raw)\n",
    "    product = ProductInfo.model_validate(data)\n",
    "    print(\"✅ Parsed keys:\", list(data.keys()))\n",
    "    print(json.dumps(product.model_dump(), indent=2))\n",
    "except Exception as e:\n",
    "    print(\"Raw output:\\n\", raw)\n",
    "    print(\"\\nValidation error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77313b",
   "metadata": {},
   "source": [
    "## Section 1: Grammar mode\n",
    "\n",
    "Constrain output to a specific grammar (e.g., names, IDs).\n",
    "\n",
    "- Docs: [Grammar mode](https://fireworks.ai/docs/structured-responses/structured-output-grammar-based)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e903e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fireworks import LLM\n",
    "\n",
    "# --- Client setup ---\n",
    "FIREWORKS_API_KEY = os.environ[\"FIREWORKS_API_KEY\"]\n",
    "MODEL_ID = \"accounts/fireworks/models/deepseek-v3p1\"\n",
    "\n",
    "llm = LLM(model=MODEL_ID, deployment_type=\"serverless\", api_key=FIREWORKS_API_KEY)\n",
    "\n",
    "# --- Blurb to extract from ---\n",
    "product_blurb = \"\"\"\n",
    "Introducing the Acme BreezeMax Pro, a whisper-quiet 16\" smart pedestal fan.\n",
    "AI auto mode adjusts airflow to room conditions. Three colors: black, white, green.\n",
    "Includes a 2-year warranty. MSRP 139 USD. Perfect for large rooms.\n",
    "\"\"\"\n",
    "\n",
    "# --- Grammar in BNF (GBNF) format ---\n",
    "price_grammar = \"\"\"\n",
    "root ::= number\n",
    "number ::= DIGITS\n",
    "DIGITS ::= DIGIT | DIGIT DIGITS\n",
    "DIGIT ::= \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\"\n",
    "\"\"\"\n",
    "\n",
    "# --- Messages ---\n",
    "system_msg = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are an assistant that extracts the price from a product summary. \"\n",
    "        \"Return ONLY the number (no currency symbol, no text).\"\n",
    "    )\n",
    "}\n",
    "user_msg = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"Here is the summary:\\n\\n{product_blurb}\\n\\nWhat is the price?\"\n",
    "}\n",
    "\n",
    "# --- Call using grammar mode ---\n",
    "resp = llm.chat.completions.create(\n",
    "    messages=[system_msg, user_msg],\n",
    "    temperature=0.1,\n",
    "    response_format={\"type\": \"grammar\", \"grammar\": price_grammar},\n",
    ")\n",
    "\n",
    "# --- Output ---\n",
    "print(\"Extracted price:\", resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24723888",
   "metadata": {},
   "source": [
    "## Section 2: Deployments with firectl\n",
    "\n",
    "Create and manage deployments from the command line.\n",
    "\n",
    "- Docs: [firectl](https://fireworks.ai/docs/tools-sdks/firectl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65646ba",
   "metadata": {},
   "source": [
    "#### Install firectl with Homebrew (macOS)\n",
    "\n",
    "```bash\n",
    "brew tap fw-ai/firectl\n",
    "brew install firectl\n",
    "```\n",
    "\n",
    "#### Verify auth\n",
    "\n",
    "```bash\n",
    "firectl signin\n",
    "firectl whoami\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1b6b9",
   "metadata": {},
   "source": [
    "#### Create a small deployment (example: Qwen3 0.6B)\n",
    "**Confirm the exact model ID in the Model Library for your account**\n",
    "\n",
    "```bash\n",
    "firectl create deployment accounts/fireworks/models/qwen3-0p6b\n",
    "```\n",
    "\n",
    "**List deployments**\n",
    "\n",
    "```bash\n",
    "firectl list deployments\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sending a request to my deployment\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "url = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
    "payload = {\n",
    "  \"model\": \"accounts/jmiano888-83b646/deployedModels/qwen3-0p6b-rno799u3\",\n",
    "  \"max_tokens\": 5120,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 40,\n",
    "  \"presence_penalty\": 0,\n",
    "  \"frequency_penalty\": 0,\n",
    "  \"temperature\": 0.6,\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hello, how are you?\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "headers = {\n",
    "  \"Accept\": \"application/json\",\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {os.environ['FIREWORKS_API_KEY_2']}\"\n",
    "}\n",
    "resp = requests.request(\"POST\", url, headers=headers, data=json.dumps(payload))\n",
    "print(resp.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3dcb46",
   "metadata": {},
   "source": [
    "## Section 3 — Fine-tuning overview\n",
    "\n",
    "Approaches:\n",
    "- Supervised fine-tuning (SFT)\n",
    "- Reinforcement fine-tuning (RFT)\n",
    "- Direct Preference Optimization (DPO)\n",
    "\n",
    "Goal: get a small, specialized model to match a larger general model on your task.\n",
    "\n",
    "Docs:\n",
    "- Fine-tuning overview: `https://fireworks.ai/docs/fine-tuning/finetuning-intro`\n",
    "- Examples and guides: `https://fireworks.ai/docs/examples/introduction`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd6246e",
   "metadata": {},
   "source": [
    "## Section 4 — What can you build?\n",
    "\n",
    "Examples:\n",
    "- Chat assistants and copilots (knowledge-grounded, tools, JSON/Grammar outputs)\n",
    "- RAG search over docs with embeddings\n",
    "- Image understanding and captioning\n",
    "- Meeting/phone call voice assistants (streaming STT + LLM)\n",
    "- Agents that call APIs (function calling)\n",
    "\n",
    "Call to action:\n",
    "- Start with the Model Library and start applying SoTA models to your use-cases\n",
    "- Try a new small model on your task (e.g., Qwen3 0.6B) and see how it performs; fine-tune for even better results!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
